# Fleet Configuration for Manufacturing Sites
# Supports both cloud and local LLM providers for air-gapped environments

# ============================================================================
# LLM Provider Configuration
# ============================================================================
# Supported providers: vllm, llama_cpp, anthropic, openai, openai_compatible
#
# PRIMARY: Use local providers for air-gapped industrial environments
#   - vllm: High-throughput production deployments (RECOMMENDED)
#   - llama_cpp: Edge deployment on industrial PCs
#
# Recommended local models:
#   - minimax-m2.1: Strong multilingual and code capabilities
#   - GLM-4.7: Excellent code generation and reasoning
#
# Environment variables override these settings:
#   LLM_PROVIDER, LLM_MODEL, LLM_BASE_URL

llm:
  # Local vLLM (default - no auth required)
  provider: "vllm"
  model: "minimax-m2.1"
  base_url: "http://localhost:8000"

  # Cloud provider examples (require API keys):

  # Anthropic Claude
  # provider: "anthropic"
  # model: "claude-sonnet-4-20250514"

  # OpenAI
  # provider: "openai"
  # model: "gpt-4o"

  # Other local provider examples:

  # vLLM with GLM-4.7
  # provider: "vllm"
  # model: "THUDM/glm-4.7"
  # base_url: "http://localhost:8000"

  # llama.cpp with GLM-4.7 (edge deployment)
  # provider: "llama_cpp"
  # model: "/models/glm-4.7.Q4_K_M.gguf"
  # n_gpu_layers: -1  # Use all GPU layers

  # llama.cpp with MiniMax-M2.1
  # provider: "llama_cpp"
  # model: "/models/MiniMax-M2.1.Q4_K_M.gguf"
  # n_gpu_layers: -1

  # OpenAI-compatible endpoint (for custom inference servers)
  # provider: "openai_compatible"
  # model: "minimax-m2.1"
  # base_url: "http://localhost:8080/v1"

  # Common settings
  temperature: 0.0
  max_tokens: 4096
  timeout: 120

# ============================================================================
# Manufacturing Sites
# ============================================================================
sites:
  - name: "Plant-01-Assembly"
    location: "Detroit, MI"
    plc_type: "Siemens S7-1500"
    firmware_version: "2.9.3"
    line_type: "Assembly"
    repo_path: "/repos/plant-01-assembly"
    safety_rating: "SIL-2"
    tags: ["siemens", "assembly", "midwest"]

  - name: "Plant-01-Welding"
    location: "Detroit, MI"
    plc_type: "Siemens S7-1500"
    firmware_version: "2.9.3"
    line_type: "Welding"
    repo_path: "/repos/plant-01-welding"
    safety_rating: "SIL-3"
    tags: ["siemens", "welding", "midwest", "high-safety"]

  - name: "Plant-02-Assembly"
    location: "Chicago, IL"
    plc_type: "Allen-Bradley ControlLogix"
    firmware_version: "32.011"
    line_type: "Assembly"
    repo_path: "/repos/plant-02-assembly"
    safety_rating: "SIL-2"
    tags: ["rockwell", "assembly", "midwest"]

  - name: "Plant-02-Packaging"
    location: "Chicago, IL"
    plc_type: "Allen-Bradley ControlLogix"
    firmware_version: "32.011"
    line_type: "Packaging"
    repo_path: "/repos/plant-02-packaging"
    safety_rating: "SIL-1"
    tags: ["rockwell", "packaging", "midwest"]

  - name: "Plant-03-CNC"
    location: "Austin, TX"
    plc_type: "Siemens S7-1200"
    firmware_version: "4.5.0"
    line_type: "Machining"
    repo_path: "/repos/plant-03-cnc"
    safety_rating: "SIL-2"
    tags: ["siemens", "cnc", "southwest"]

# ============================================================================
# Agent Configuration
# ============================================================================
agent:
  max_turns: 10
  max_retries: 3
  timeout: 300  # seconds

  # MCP Tools available to agent (limited for predictability)
  tools:
    - "verify"
    - "git_diff"
    - "ripgrep"

# ============================================================================
# Verification Settings
# ============================================================================
verification:
  # Deterministic verifiers (run in order)
  verifiers:
    - type: "compiler"
      required: true
      timeout: 300

    - type: "safety"
      required: true
      timeout: 600
      critical: true  # Hard stop on failure

    - type: "simulation"
      required: false  # Optional, runs if available
      timeout: 900

  # LLM judge settings
  judge:
    enabled: true
    confidence_threshold: 0.7  # Minimum confidence to approve
    # Uses same LLM provider as main config, or specify:
    # model: "gpt-4o"

# ============================================================================
# Change Management
# ============================================================================
change_management:
  approval_required: true
  safety_review_required: true
  simulation_before_deploy: true
  create_backup: true

# ============================================================================
# Logging and Observability
# ============================================================================
logging:
  level: "INFO"
  format: "json"  # json or text

  # Telemetry
  mlflow_tracking: true
  mlflow_uri: "http://localhost:5000"

  # Audit logging (required for compliance)
  audit_log: "logs/audit.jsonl"

  # Session tracing
  trace_sessions: true
  trace_llm_calls: true

# ============================================================================
# API Configuration
# ============================================================================
api:
  enabled: true
  host: "0.0.0.0"
  port: 8080
  cors_origins: ["*"]  # Restrict in production
